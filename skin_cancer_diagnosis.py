# -*- coding: utf-8 -*-
"""Skin cancer diagnosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-aiUybPAuLW9T40fRUdIQ4X9tG7XvMz1
"""

# 1. Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
!pip install tensorflow scikit-learn matplotlib gdown

# 2. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ùˆ Ù…Ø¯Ù„ Ø³Ø§Ø²ÛŒ Ùˆ ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ú©Ø§Ø±Ø¨Ø± Ùˆ Ú©Ø§Ø± Ø¨Ø§ Ù…Ø­ÛŒØ· Ú©ÙˆÙ„Ø¨
import os
import zipfile
import shutil
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from google.colab import files
from IPython.display import display, Image
import tensorflow as tf
import ipywidgets as widgets
from IPython.display import clear_output

# ØªØ¹Ø±ÛŒÙ Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡â€ŒÙ…Ø¯Ù„
model_path = 'skin_cancer_model.h5'

# 3. Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§Ø³Øª ÙÙ‚Ø· Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
if not os.path.exists('ham10000.zip'):
    !gdown --id 1mTK7p5ZoCyYl9Tx1eKdS2wTi-4pqaCAH -O ham10000.zip
if not os.path.exists('healthy_skin.zip'):
    !gdown --id 1NEWYquTpQhoPOg0eAQxR_mzg3JoTaSNc -O healthy_skin.zip

# 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
if not os.path.exists('ham10000'):
    with zipfile.ZipFile('ham10000.zip', 'r') as zip_ref:
        zip_ref.extractall('ham10000')
if not os.path.exists('healthy_skin'):
    with zipfile.ZipFile('healthy_skin.zip', 'r') as zip_ref:
        zip_ref.extractall('healthy_skin')

# 5. Ø³Ø§Ø®Øª Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ ØªØµØ§ÙˆÛŒØ± ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ù†Ø¯
if not os.path.exists('dataset/train/cancer'):
    os.makedirs('dataset/train/cancer', exist_ok=True)
    os.makedirs('dataset/train/healthy', exist_ok=True)

    cancer_images = os.listdir('ham10000')
    for img in cancer_images[:900]:
        shutil.move(f'ham10000/{img}', f'dataset/train/cancer/{img}')

    healthy_images = os.listdir('healthy_skin')
    for img in healthy_images[:900]:
        shutil.move(f'healthy_skin/{img}', f'dataset/train/healthy/{img}')

# 6. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø«Ù„ ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµØ§ÙˆÛŒØ±
image_size = (128, 128)
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
train_generator = datagen.flow_from_directory(
    'dataset/train', target_size=image_size, batch_size=32, class_mode='categorical', subset='training')
val_generator = datagen.flow_from_directory(
    'dataset/train', target_size=image_size, batch_size=32, class_mode='categorical', subset='validation')

# 7. Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ØŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
if os.path.exists(model_path):
    print("âœ… Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² ÙØ§ÛŒÙ„ ...")
    model = load_model(model_path)
else:
    print("ğŸ“Œ Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª. Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ ...")
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
        MaxPooling2D(2,2),
        Conv2D(64, (3,3), activation='relu'),
        MaxPooling2D(2,2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.3),
        Dense(2, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    history = model.fit(train_generator, epochs=10, validation_data=val_generator, callbacks=[early_stop])
    model.save(model_path)
    print("âœ… Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

# 8. ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØµÙˆÛŒØ±
def predict_image(img_path):
    img = load_img(img_path, target_size=image_size)
    img_array = img_to_array(img)/255.0
    img_array = np.expand_dims(img_array, axis=0)
    pred = model.predict(img_array)
    class_index = np.argmax(pred)
    if class_index == 0:
        result = "Ù¾ÙˆØ³Øª Ø³Ø±Ø·Ø§Ù†ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯"
    else:
        result = "Ù¾ÙˆØ³Øª Ø³Ø§Ù„Ù… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯"
    display(Image(filename=img_path))
    print("Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ:")
    print(result[::1])

# 9. ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ ØªØ´Ø®ÛŒØµ
def interaction_loop():
    confirm_text = widgets.Text(
        value='', placeholder='Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯: Ø¨Ù„Ù‡', description='Ø§Ø¯Ø§Ù…Ù‡ØŸ', disabled=False)
    button = widgets.Button(description="ØªØ£ÛŒÛŒØ¯")

    def on_button_clicked(b):
        clear_output(wait=True)
        if confirm_text.value.strip() == 'Ø¨Ù„Ù‡':
            uploaded = files.upload()
            for fn in uploaded.keys():
                predict_image(fn)
            interaction_loop()   # Ø§Ø¬Ø±Ø§ÛŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ø±Ø§ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø¹Ø¯ÛŒ
        else:
            print("Ù¾Ø§ÛŒØ§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡.")

    button.on_click(on_button_clicked)
    display(confirm_text, button)

interaction_loop()